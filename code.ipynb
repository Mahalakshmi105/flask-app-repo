{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Comparative Analysis of Machine Learning Models for Accurate House Price Prediction*** \n",
    "\n",
    "This project outlines the process of building a machine learning pipeline to predict housing prices using the `USA_Housing` dataset. The pipeline includes data preprocessing, training multiple models, saving artifacts, and preparing the solution for deployment on the cloud.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.  **OVERVIEW OF THE WORKFLOW**\n",
    "\n",
    "1. **Data Loading and Cleaning**: Load the dataset and handle missing values.\n",
    "2. **Data Preprocessing**: Select features, scale data, and split into training and testing sets.\n",
    "3. **Model Training**: Train three regression models â€” Decision Tree Regressor, Support Vector Regressor, and Gradient Boosting Regressor.\n",
    "4. **Model Evaluation**: Compute RMSE to evaluate performance.\n",
    "5. **Save Artifacts**: Save trained models and scalers for deployment.\n",
    "6. **Deployment Preparation**: Test predictions with dummy data for deployment validation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **CODE IMPLEMENTATION**\n",
    "\n",
    "**IMPORTING THE NECESSARY LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOADING AND CLEANING THE DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data = pd.read_csv('USA_Housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and Target\n",
    "X = data.drop(['Price', 'Address'], axis=1)\n",
    "y = data['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL TRAINING AND SAVING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_tree_model.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1: Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train, y_train)\n",
    "joblib.dump(dt, 'decision_tree_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2: Support Vector Regressor\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "joblib.dump(svr, 'svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gradient_boosting_model.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 3: Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "joblib.dump(gbr, 'gradient_boosting_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL EVALUATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE: 182039.3704965961\n",
      "SVR RMSE: 350941.5597254943\n",
      "Gradient Boosting RMSE: 109476.65761496617\n",
      "Models and scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "models = {'Decision Tree': dt, 'SVR': svr, 'Gradient Boosting': gbr}\n",
    "for name, model in models.items():\n",
    "    predictions = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    print(f'{name} RMSE: {rmse}')\n",
    "\n",
    "print(\"Models and scaler saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTING PREDICTIONS WITH DUMMY DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for row 1: $2,864,219.79\n",
      "Prediction for row 2: $2,864,219.79\n",
      "Prediction for row 3: $2,864,219.79\n",
      "Prediction for row 4: $2,864,219.79\n",
      "Prediction for row 5: $2,864,219.79\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Dummy Data: avg_area_income, avg_area_house_age, avg_area_rooms, avg_area_bedrooms, area_population\n",
    "dummy_data = [\n",
    "    [85.0, 20.0, 7.0, 3.0, 150.0],\n",
    "    [90.5, 25.0, 8.0, 3.5, 200.0],\n",
    "    [75.0, 15.0, 6.5, 2.5, 120.0],\n",
    "    [92.0, 30.0, 9.0, 4.0, 180.0],\n",
    "    [80.5, 18.0, 7.5, 3.0, 160.0]\n",
    "]\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = joblib.load('gradient_boosting_model.pkl')\n",
    "\n",
    "# Predict house prices for dummy data\n",
    "for i, data in enumerate(dummy_data):\n",
    "    prediction = model.predict([data])\n",
    "    print(f\"Prediction for row {i+1}: ${prediction[0]:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
